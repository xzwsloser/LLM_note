# Chapter1: NLP基础概念

## NLP任务

### 中文分词

中文中词与词之间没有明显分割, **所以中文分词成为了中文文本处理的首要步骤, 目的是把连续的中文文本切分为有意义的词汇序列**,  例如:

```text
英文输入：The cat sits on the mat.
英文切割输出：[The | cat | sits | on | the | mat]
中文输入：今天天气真好，适合出去游玩.
中文切割输出：["今天", "天气", "真", "好", "，", "适合", "出去", "游玩", "。"]
```

### 子词切分

> 注意区分与 `word2vec` 中的 `fasttext` 的区别, `word2vec` 是训练词的向量表示, 子词切分是一个具体的 `NLP`  任务, 主要目的是可以训练出一个可以切分子词的一个模型

常见的子词切分的方法, 比如 `Byte Pair Encoding(BPE)`, `WordPrice`, `Unigram` 等, 一个具体任务例如:

```Text
输入：unhappiness

不使用子词切分：整个单词作为一个单位，输出：“unhappiness”
使用子词切分（假设BPE算法）：单词被分割为：“un”、“happi”、“ness”
```

### 词性标注

词性标注类似于词分类的任务, 也就是为文本中的每一个单词分配一个词性标签, 例如 `n, adj, adv` 等, 词性标注任务对于一些高级 `NLP` 任务(例如理解句子结构、进行句法分析等任务)比较重要 ; 同时由于语法的限制, 词性标注任务一般可以使用机器学习模型进行解决, 例如隐式马尔科夫链等 

### 文本分类

也就是按照文本内容进行分类, 常用的模型例如 `fasttext、TextCNN` 等, 例如:

```text
文本：“NBA季后赛将于下周开始，湖人和勇士将在首轮对决。”
类别：“体育”

文本：“美国总统宣布将提高关税，引发国际贸易争端。”
类别：“政治”

文本：“苹果公司发布了新款 Macbook，配备了最新的m3芯片。”
类别：“科技”
```

### 实体识别

给定一段文本, 自动识别文本中具有特定意义的实体, 并且分类为预定义的类别, 例如人名、地点、组织、日期等 ; 可以用于信息提取、知识图谱构建等, 例如:

```Text
输入：李雷和韩梅梅是北京市海淀区的居民，他们计划在2024年4月7日去上海旅行。

输出：[("李雷", "人名"), ("韩梅梅", "人名"), ("北京市海淀区", "地名"), ("2024年4月7日", "日期"), ("上海", "地名")]
```

### 关系抽取

也就是从目标文本中识别实体之间的语义关系, 比如因果关系、拥有关系、地理位置关系等, 也是对于一些比较复杂的机器学习任务有一定的帮助, 例如:

```Text
输入：比尔·盖茨是微软公司的创始人。

输出：[("比尔·盖茨", "创始人", "微软公司")]
```

### 文本摘要

文本摘要是 `NLP` 中一个比较重要的任务, 目的是可以生成一段简洁准确的摘要, 可以用于概括原文内容, 可以分为两大类:

- 抽取式摘要: 直接从原文中选取关键句子或者短语组成摘要
- 生成式摘要: 基于文本内容集进行重新阻止, 并且生成新的内容

### 机器翻译

机器翻译是 `NLP` 中一项核心任务, 表示使用计算机程序将一种自然语言自动翻译成另外一种自然语言

### 自动问答

`QA` 是 `NLP` 中的一个高级任务, 默认人类理解并且回答问题的能力, 涉及了多个`NLP`子任务, 例如信息检索、文本理解、知识表示和推理等

`QA` 分类:  

- 检索式问答(利用搜索引擎从大量文本中检索)
- 知识库问答(通过结构化知识库来回答问题, `RAG`)
- 社区问答(依赖于用户生成的回答数据)

## 文本表示的发展历程

文本表示: 把自然语言转换为计算机可以处理的形式, 比如向量等形式

### 词向量

最早提出的词向量模型就是 `One-Hot` 模型,  但是缺点很明显, 利用  `One-Hot` 编码会导致词向量稀疏, 浪费的空间比较多

### 语言模型

`N-gram` 模型可以用于 `word2vec`, 在这一个模型中, 任务一个词的出现概率依赖于这一个词前面的词

### Word2Vec

`word2vec` 是一种流行的词嵌入技术, 是一种基于神经网络模型的语言模型,  和上面不同的是, `word2vec` 考虑中心词和周围词之间的关系, 主要包含两种架构: 连续词袋模型(`CBOW`) 以及 跳元模型(`Skip-Gram`) , 同时演化处其他词嵌入模型, 例如 `GloVe` 和 `fastText` 等

### ELMo

`ELMo` 把预训练的思想引入到词向量的生成中, 使用双向 `LSTM` 结构, 从而捕捉到词汇的上下文信息 ; 首先在大型语料库上训练语言模型, 得到词向量模型, 然后在特定任务上对模型进行微调, 得到适合该任务的模型

`ELMo` 采用两阶段过程: 第一个阶段使用语言模型进行预训练, 第二个阶段在做特定任务的过程中, 从预训练网络中提取对应的单词的词向量作为新特征补充到下游任务中

























